<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
    <head>
        <title>Jayant Thatte </title>
        <meta charset="utf-8"> 
        <meta name="viewport" content="width=device-width, initial-scale=1">

        <link rel="shortcut icon" type="image/x-icon" href="/im/favicon.ico">
        <link href="https://fonts.googleapis.com/css?family=Istok+Web" rel="stylesheet">
        <link href="css/jayant.css" rel="stylesheet">
        <link href="vendor/css/bootstrap.min.css" rel="stylesheet">
        <link href="vendor/css/bootstrap-theme.min.css" rel="stylesheet">
        <link href="vendor/css/academicons.min.css" rel="stylesheet">
        <link href="vendor/css/font-awesome.min.css" rel="stylesheet">

    </head>
    <body>

      
        <nav class="navbar navbar-default navbar-fixed-top" id="site_nav">
            <div class="container-fluid">
                <!-- Brand and toggle get grouped for better mobile display -->
                <div class="navbar-header">
                    <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar-collapse-1" aria-expanded="false">
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                    <a class="navbar-brand" href="#top" style="font-size:24px">Jayant Thatte</a>
                </div>

                <!-- Collect the nav links, forms, and other content for toggling -->
                <div class="collapse navbar-collapse" id="navbar-collapse-1">
                    <ul class="nav navbar-nav">
                        <!--<li><a href="#news">News <span class="sr-only">(current)</span></a></li>-->
                        <li><a href="#education">Education </a></li>
                        <li><a href="#research">Research </a></li>
                        <li><a href="#awards">Awards </a></li>
                        <li><a href="#publications">Publications </a></li>
                        <li><a href="#projects">Projects </a></li>
                        <li><a href="#teaching">Teaching </a></li>
                        <li><a href="#experience">Experience </a></li>
                        <li><a href="#skills">Skills </a></li>
                        <li><a href="#contact">Contact </a></li>
                    </ul>
                    
                    <ul class="nav navbar-nav navbar-right">
                        <!--
						<li>
                            <a href="http://github.com/davelindell" target="_blank">
                                <i class="fa fa-lg fa-github" aria-hidden="true"></i>
                            </a>
                        </li>
                        -->
						<li>
                            <a href="https://scholar.google.co.in/citations?user=pSNU6c8AAAAJ&hl=en" target="_blank">
                                <i class="ai ai-lg ai-google-scholar" aria-hidden="true"></i>
                            </a>
                        </li>
						<li>
                            <a href="https://www.linkedin.com/in/jayant-thatte/" target="_blank">
                                <i class="fa fa-lg fa-linkedin" aria-hidden="true"></i>
                            </a>
                        </li>
                    </ul>
                </div><!-- /.navbar-collapse -->

            </div><!-- /.container-fluid -->
        </nav>

        <div class = "container" id="top">
            <div class="row">
                <div class="col-md-6">
                    <div style='font-size: 4em; font-weight: bold; padding-bottom: 0.0em;'>Jayant Thatte, Ph.D.</div>

                    <div style='font-size: 2em; font-weight: bold; padding-bottom: 0.3em;'> 
                        Software Engineer, <a href="https://waymo.com">Waymo LLC</a>
                    </div>

                    <a href="data/cv.pdf" target="_blank" class="btn btn-primary" style="padding: 0.5em; margin-top:-20px; margin-right:20px;">
                        <i class="fa fa-download"></i> Download CV
                    </a>
                    <!--
					<a href="http://github.com/davelindell" target="_blank" style="margin:20px">
                        <i class="fa fa-3x fa-github" aria-hidden="true"></i>
                    </a>
					-->
                    <a href="https://scholar.google.co.in/citations?user=pSNU6c8AAAAJ&hl=en" target="_blank" style="margin:20px">
                        <i class="ai ai-3x ai-google-scholar" aria-hidden="true"></i>
                    </a>
                    <a href="https://www.linkedin.com/in/jayant-thatte/" target="_blank" style="margin:20px">
                        <i class="fa fa-3x fa-linkedin" aria-hidden="true"></i>
                    </a>



                </div>

                <div class="col-md-6">
                    <div style='font-size: 5em; font-weight: bold; padding-bottom: 0.3em;'> 
                        <a href="im/jayant.png">
                            <img src="im/jayant.png"
                              width="500" style="border-radius: 10px; margin: 10px; max-width: none; margin-left: 0px; margin-top: 0px"
                              alt="Jayant Thatte"/>
                        </a>
                    </div>
                </div>
            </div>

            <div class="row">
                <div class="col-md-12" style='font-size:1.5em'>
                    I recently graduated with a Ph.D. in electrical engineering from Stanford University. I am excited to soon start working at Waymo on their self-drivng car effort. My areas of expertise include computer vision, virtual reality, image processing, and computer graphics. I completed my doctoral research in <a href="https://web.stanford.edu/~bgirod/People.html", target="_blank">Stanford's Image Video and Multimedia Systems (IVMS) Lab</a> and was advised by <a href="https://web.stanford.edu/~bgirod", target="_blank">Prof. Bernd Girod</a>. My research focused on enabling real-time head-motion parallax in virtual reality for real-world content. To that end, I designed and built a custom camera rig, proposed a novel depth-fusion algorithm for robust 3-D reconstruction, explored novel scene representations, and developed a custom real-time graphics renderer to demonstrate the head-motion parallax on Oculus Rift headset at the recommended resolution and framerate. My professional interests also include deep learning methods, light fields, and keypoint detectors and feature descriptors. 
                </div>  
            </div>

            <!--<h1 id="news">News</h1>
            <div class="row">
            <table class="table table-hover">
                <tr>
                    <td  class="col-md-2">
                        <div style="font-size:1.5em;"> 
                           February 2018 
                        </div>
                    </td>
                    <td class="col-md-10">
                        <div style="font-size:1.5em;">
                            Our paper on virtual reality with six degrees of freedom was published.<br>
                            <a style="cursor: pointer;" class='flip' onclick="$(this).next('.panel').slideToggle();"> [Abstract]</a>
                            <a style="cursor: pointer;" href="https://www.ingentaconnect.com/contentone/ist/ei/2018/00002018/00000005/art00009"> [Webpage]</a>
                            <a style="cursor: pointer;" href="data/ei18.pdf"> [PDF]</a>
                            <a style="cursor: pointer;" href="https://www.youtube.com/watch?v=tDC-gHBCTn8"> [Video]</a>
                        </div>
                        <div class="panel" style="display:none; font-size:18px; text-align: justify;">
							<p>Allowing viewers to explore virtual reality in a head-mounted display with six degrees of freedom (6-DoF) greatly enhances the associated immersion and comfort. It makes the experience more compelling compared to a fixed-viewpoint 2-DoF rendering produced by conventional algorithms using data from a stationary camera rig. In this work, we use subjective testing to study the relative importance of, and the interaction between, motion parallax and binocular disparity as depth cues that shape the perception of 3D environments by human viewers. Additionally, we use the recorded head trajectories to estimate the distribution of the head movements of a sedentary viewer exploring a virtual environment with 6-DoF. Finally, we demonstrate a real-time virtual reality rendering system that uses a Stacked OmniStereo intermediary representation to provide a 6-DoF viewing experience by utilizing data from a stationary camera rig. We outline the challenges involved in developing such a system and discuss the limitations of our approach.</p>
						</div>
                    </td>
                </tr>

                <tr>
                    <td  class="col-md-2">
                        <div style="font-size:1.5em;"> 
                           September 2018 
                        </div>
                    </td>
                    <td class="col-md-10">
                        <div style='font-size:1.5em;'>
                            Our poster on the effect of motion parallax and binocular stereopsis on viewer preference and size perception in virtual reality was presented at ECCV. I also gave a research talk at the Chair of Media Technology in TU Munich.
							<a style="cursor: pointer;" href="https://360pi.github.io"> [Website]</a>
                            <a style="cursor: pointer;" href="data/eccv18_abs.pdf"> [Structured Abstract]</a>
                            <a style="cursor: pointer;" href="data/eccv18.pdf"> [Poster]</a>
                            <a style="cursor: pointer;" href="data/tum18.pptx"> [Talk Slides]</a>
                        </div>
                    </td>
                </tr>
            </table>
            </div>-->

            <h1 id="education">Education</h1>
            <div class="row">
            <table class="table table-hover">

                <tr>
                    <td class="col-md-1"> 
                        <div style='font-size:1.5em'>
                            <a href=""> 
                                <img src="im/su_logo.png"
                                  width="95" style="border-radius: 33px; margin: 10px; max-width: none; margin-left: 0px; margin-top: 0px"
                                  alt="stanford"/>
                            </a> 
                        </div>
                    </td>
                    <td  class="col-md-2">
                        <div style="font-size:1.5em; margin-top: 30px;"> 
                            2014-2020
                        </div>
                    </td>
                    <td class="col-md-9">
                        <div style='font-size:1.5em'>
                            <strong> Stanford University </strong> <br />
                            Ph.D Electrical Engineering<br>
							CGPA: 3.97 / 4.0
                            <a style="cursor: pointer;" href="data/stanford_transcript.pdf"> [Transcript]</a>
                        </div>
                    </td>
                </tr>
                <tr>
                    <td class="col-md-1"> 
                        <div style='font-size:1.5em'>
                            <a href="http://www.iitm.ac.in"> 
                                <img src="im/iitm_logo.png"
                                  width="81" style="border-radius: 39px; margin: 10px; max-width: none; margin-left: 12px; margin-top: 12px"
                                  alt="IIT Madras"/>
                            </a> 
                        </div>
                    </td>
                    <td  class="col-md-2">
                        <div style="font-size:1.5em; margin-top: 20px;"> 
                            2009-2014
                        </div>
                    </td>
                    <td class="col-md-9">
                        <div style='font-size:1.5em'>
                            <strong> Indian Institute of Technology (IIT) Madras, India </strong> <br />
                            B.Tech.-M.Tech. (joint)  Electrical Engineering<br>
							Minor: Economics<br>
							CGPA: 9.37 / 10.0
                            <a style="cursor: pointer;" href="data/iitm_transcript.pdf"> [Transcript]</a>
							<br><br>
							<i>Philips India Award for highest cumulative GPA in Electrical Engineering at the time of graduation</i> <br /> 
                        </div>
                    </td>
                </tr>
            </table>
            </div>


            <h1 id="research">Research</h1>
            <div class="row">
            <table class="table table-hover">

                <tr>
                    <td class="col-md-2" > 
                        <div style="font-size:1.5em;"> 
                            2014-2020
                        </div>
                    </td>
                    <td class="col-md-10 col-md-offset-0">
                        <div style='font-size:1.5em'>
                            <strong> Stanford University</strong>, Ph.D. Student <br />
                            <i>Advisor (2015-present):</i> <a style="cursor: pointer;" href="https://web.stanford.edu/~bgirod/">Prof. Bernd Girod</a> <br />
                            <i>Area:</i> Virtual reality, light fields, computer graphics<br />
                            <i>Project:</i> Data representations for live-action virtual reality with motion parallax, real-time six degrees of freedom 360 rendering, effects of motion parallax and binocular stereopsis on viewer preference and subjective visual perception in virtual reality
                        </div>
                    </td>
                </tr>

                <tr>
                    <td class="col-md-2" > 
                        <div style="font-size:1.5em;"> 
                            2012-2014
                        </div>
                    </td>
                    <td class="col-md-10 col-md-offset-0">
                        <div style='font-size:1.5em'>
                            <strong> Indian Institute of technology (IIT) Madras</strong>, M.Tech. Student <br />
                            <i>Advisor:</i> <a style="cursor: pointer;" href="https://www.cse.iitm.ac.in/~shankar/">Dr. Shankar Balachandran</a> <br />
                            <i>Area:</i> Fourier Transform on Galois Field, digital logic synthesis, discrete math<br />
                            <i>Project:</i> Predicting the post-synthesis complexity of digital logic using Fourier Transform on Boolean Cube
							<a style="cursor: pointer;" href="data/mtech.pdf"> [Master Thesis]</a>
                        </div>
                    </td>
                </tr>
                
            </table>
            </div>
            
			<h1 id="awards">Awards</h1>
            <div class="row">
            <table class="table table-hover">

                <tr>
                    <td class="col-md-3"> 
                        <div style='font-size:1.5em'>
                            <a href=""> 
                                <img src="im/scien17.png"
                                  width="285" style="border-radius: 0px; margin: 10px; max-width: none; margin-left: 0px; margin-top: 0px"
                                  alt="SCIEN 2017"/>
                            </a> 
                        </div>
                    </td>
                    <td  class="col-md-2">
                        <div style="font-size:1.5em; margin-top: 30px;"> 
                            December 2017
                        </div>
                    </td>
                    <td class="col-md-7">
                        <div style='font-size:1.5em'>
                            <strong>SCIEN Distinguished Poster Award by NVIDIA</strong> <br />
                            <strong>J. Thatte</strong>, B. Girod, "Stacked OmniStereo for Virtual Reality with Six Degrees of Freedom"
                            <a style="cursor: pointer;" href="data/scien15.pdf"> [Poster]</a>
                        </div>
                    </td>
                </tr>
                <tr>
                    <td class="col-md-3"> 
                        <div style='font-size:1.5em'>
                            <a href=""> 
                                <img src="im/sps16.gif"
                                  width="285" style="border-radius: 0px; margin: 10px; max-width: none; margin-left: 0px; margin-top: 0px"
                                  alt="IEEE SPS"/>
                            </a> 
                        </div>
                    </td>
                    <td  class="col-md-2">
                        <div style="font-size:1.5em; margin-top: 30px;"> 
                            September 2016
                        </div>
                    </td>
                    <td class="col-md-7">
                        <div style='font-size:1.5em'>
                            <strong>IEEE SPS Best Conference Paper for Industry</strong> <br />
                            <strong>J. Thatte</strong>, J. -B. Boin, H. Lakshman, G. Wetzstein, B. Girod, “Depth Augmented Stereo Panorama for Cinematic Virtual Reality with Focus Cues”, <i>IEEE International Conf. on Image Processing (ICIP)</i>, 2016.
						<a style="cursor: pointer;" class='flip' onclick="$(this).next('.panel').slideToggle();"> [Abstract]</a>
						<a style="cursor: pointer;" href="https://ieeexplore.ieee.org/document/7532622"> [Webpage]</a>
						<a style="cursor: pointer;" href="data/icip16.pdf"> [PDF]</a>
						<a style="cursor: pointer;" href="data/icme16_icip16.zip"> [Supplement]</a>
						<a style="cursor: pointer;" href="https://signalprocessingsociety.org/sites/default/files/uploads/get_involved/awards/Conference_Best_Paper_Award_for_Industry.pdf"> [Award]</a>
                        </div>
                        <div class="panel" style="display:none; font-size:18px; text-align: justify;">
							<p>Cinematic virtual reality (VR) aims to provide immersive visual experiences of real-world scenes on head-mounted displays. Current cinematic VR systems support stereo cues, but not focus cues that are important for depth perception and comfortable viewing. We propose a new content representation, depth augmented stereo panorama (DASP), which permits generating light fields (LFs) across the observer’s pupils, achieving an order of magnitude reduction in data requirements compared to the existing techniques. The LF generation and refocusing capabilities of DASP are evaluated for both, computer-generated and real scenes. Results indicate that DASP can successfully create stereo as well as support focus cues.</p>
						</div>
                    </td>
                </tr>
                <tr>
                    <td class="col-md-3"> 
                        <div style='font-size:1.5em'>
                            <a href=""> 
                                <img src="im/scien15.png"
                                  width="285" style="border-radius: 0px; margin: 10px; max-width: none; margin-left: 0px; margin-top: 0px"
                                  alt="SCIEN 2015"/>
                            </a> 
                        </div>
                    </td>
                    <td  class="col-md-2">
                        <div style="font-size:1.5em; margin-top: 30px;"> 
                            December 2015
                        </div>
                    </td>
                    <td class="col-md-7">
                        <div style='font-size:1.5em'>
                            <strong>SCIEN Distinguished Poster Award by Apple</strong> <br />
                            <strong>J. Thatte</strong>, B. Girod, "Depth Augmented Stereo Panorama for Cinematic Virtual Reality"
                            <a style="cursor: pointer;" href="data/scien17.pdf"> [Poster]</a>
                        </div>
                    </td>
                </tr>
                <tr>
                    <td class="col-md-3"> 
                        <div style='font-size:1.5em'>
                            <a href=""> 
                                <img src="im/philips.png"
                                  width="162" style="border-radius: 0px; margin: 10px; max-width: none; margin-left: 12px; margin-top: 12px"
                                  alt="Philips India"/>
                            </a> 
                        </div>
                    </td>
                    <td  class="col-md-2">
                        <div style="font-size:1.5em; margin-top: 30px;"> 
                            July 2014
                        </div>
                    </td>
                    <td class="col-md-7">
                        <div style='font-size:1.5em'>
                            <strong>Philips India Award</strong> for highest cumulative GPA at the time of graduation with B.Tech-M.Tech dual degree in electrical engineering
                        </div>
                    </td>
                </tr>
                <tr>
                    <td class="col-md-3"> 
                        <div style='font-size:1.5em'>
                            <a href=""> 
                                <img src="im/gs.png"
                                  width="95" style="border-radius: 0px; margin: 10px; max-width: none; margin-left: 12px; margin-top: 12px"
                                  alt="Philips India"/>
                            </a> 
                        </div>
                    </td>
                    <td  class="col-md-2">
                        <div style="font-size:1.5em; margin-top: 30px;"> 
                            October 2013
                        </div>
                    </td>
                    <td class="col-md-7">
                        <div style='font-size:1.5em'>
                            Ranked in top 3 nationwide (from 300 teams) in <strong>GS Quantify</strong>, a modeling and problem solving contest held by Goldman Sachs in India.<br>
                            <a style="cursor: pointer;" href="data/gsquantify.pdf"> [Contest Problems]</a>
                            <a style="cursor: pointer;" href="data/gsquantify_solutions.pptx"> [Final Presentation]</a>
                        </div>
                    </td>
                </tr>
                
				<tr>
                    <td class="col-md-3"> 
                        <div style='font-size:1.5em'>
                            <a href=""> 
                                <img src="im/iao08.png"
                                  width="285" style="border-radius: 0px; margin: 10px; max-width: none; margin-left: 12px; margin-top: 12px"
                                  alt="Philips India"/>
                            </a> 
                        </div>
                    </td>
                    <td  class="col-md-2">
                        <div style="font-size:1.5em; margin-top: 30px;"> 
                            October 2008
                        </div>
                    </td>
                    <td class="col-md-7">
                        <div style='font-size:1.5em'>
                            Represented India and won a silver medal at the XIII International Astronomy Olympiad, Trieste, Italy among teams from 22 countries
                        </div>
                    </td>
                </tr>
            </table>
			<!--<div style='font-size:1.5em'>
				To view the list of older awards (prior to 2013), click <a style="cursor: pointer;" class='flip' onclick="$(this).next('.panel').slideToggle();"> [here]</a>.
			</div>
			<div class="panel" style="display:none; font-size:18px; text-align: justify;">
				<ul><br>
				<li>WISE scholarship by the German Academic Exchange Service (DAAD) for a research internship at TU Dresden, Germany (May-July 2012)
				<br><br>
				<li>Ranked in the top 0.1% nationwide at Indian National Mathematical Olympiad (2009)
				<br><br>
				<li>Silver medal at the XIII International Astronomy Olympiad held in Italy  among participants from 22 countries (October 2008)
				<br><br>
				<li>Recipient of KVPY scholarship by Govt. of India awarded to top 0.5% of the applicants for extraordinary research aptitude (March 2008)
				<br><br>
				<li>National Talent Search scholarship by Govt. of India awarded to top 0.5% of the applicants for outstanding academic aptitude (2007)
				</ul>
			</div>
            </div>-->

            <h1 id="publications">Publications</h1>
            <div class="row">
            <table class="table table-hover">
                
				<tr>
                    <td class="col-md-3"><img width=250 src="im/vcip19.png"></td>
                    <td class="col-md-9 col-md-offset-0">
                        <div style='font-size:1.5em'>
                            <strong>J. Thatte</strong>, B. Girod, “A Statistical Model for Disocclusions in Depth-based Novel View Synthesis”, <i>IEEE Conference on Visual Communications and Image Processing</i>, 2019.
                        </div>
                        <div style='font-size:1.5em'>
                            <a style="cursor: pointer;" class='flip' onclick="$(this).next('.panel').slideToggle();"> [Abstract]</a>
                            <a style="cursor: pointer;" href="https://ieeexplore.ieee.org/document/8966071"> [Webpage]</a>
                            <a style="cursor: pointer;" href="data/vcip19.pdf"> [PDF]</a>
                            <a style="cursor: pointer;" href="data/vcip19_poster.pdf"> [Poster]</a>
                        </div>
                        <div class="panel" style="display:none; font-size:18px; text-align: justify;">
							<p>The occurrence of missing regions in output images is a critical issue when rendering a scene from novel vantage points using depth-based view synthesis. These regions typically have to be filled using inpainting algorithms, which are slow and might yield unconvincing results. Understanding the likelihood of the occurrence of these missing regions can help us design better, application-specific data representations and camera systems by knowing which vantage points should be captured and stored to minimize disocclusion holes in the synthesized novel views. In this paper, we propose a statistical model that predicts the likelihood of missing data in synthesized images as a function of the viewpoint translation. Scene-dependent model parameters are efficiently estimated using simple shift and scaling transformations on the source depth images without needing view synthesis.</p>
						</div>
                    </td>
                </tr>
				
				<tr>
                    <td class="col-md-3"><img width=250 src="im/eccv18.png"></td>
                    <td class="col-md-9 col-md-offset-0">
                        <div style='font-size:1.5em'>
                            <strong>J. Thatte</strong>, B. Girod, “The Effect of Motion Parallax and Binocular Stereopsis on Viewer Preference and Size Perception in Virtual Reality”, <i>European Conference on Computer Vision (ECCV), Workshop on 360-Degree Perception and Interaction</i>, 2018.
                        </div>
                        <div style='font-size:1.5em'>
                            <a style="cursor: pointer;" class='flip' onclick="$(this).next('.panel').slideToggle();"> [Abstract]</a>
                            <a style="cursor: pointer;" href="https://360pi.github.io/"> [Webpage]</a>
                            <a style="cursor: pointer;" href="data/eccv18_abs.pdf"> [PDF]</a>
                            <a style="cursor: pointer;" href="data/eccv18.pdf"> [Poster]</a>
                            <a style="cursor: pointer;" href="data/tum18.pptx"> [Talk Slides (TU Munich)]</a>
                        </div>
                        <div class="panel" style="display:none; font-size:18px; text-align: justify;">
							<p>The perceptions of comfort and presence in virtual reality (VR) are tightly linked to the richness of the visual cues that are made available to the viewer and the fidelity with which they are rendered. In this work, we present two subjective studies, the first of which is aimed at understanding how the quality of experience in VR is affected by the presence and absence of motion parallax and binocular stereopsis. The second one reports an illusion where, in the absence of stereo disparity, objects are perceived to be significantly larger compared to when the stereo cue is available, with the average magnification being as high as 2x for objects up-close. We conclude that while rendering the correct motion parallax is critical for mitigating visual discomfort, the viewers’ ability of accurate size perception is largely dependent on binocular stereopsis.</p>
						</div>
                    </td>
                </tr>

                <tr>
                    <td class="col-md-3"><img width=250 src="im/ei18.png"></td>
                    <td class="col-md-9 col-md-offset-0">
                        <div style='font-size:1.5em'>
                            <strong>J. Thatte</strong>, B. Girod, “Towards Perceptual Evaluation of Six Degrees of Freedom Virtual Reality Rendering from Stacked OmniStereo Representation”, <i>Photography, Mobile, and Immersive Imaging Conference, Electronic Imaging Symposium</i>, 2018.
                        </div>
                        <div style='font-size:1.5em'>
                            <a style="cursor: pointer;" class='flip' onclick="$(this).next('.panel').slideToggle();"> [Abstract]</a>
                            <a style="cursor: pointer;" href="https://www.ingentaconnect.com/contentone/ist/ei/2018/00002018/00000005/art00009"> [Webpage]</a>
                            <a style="cursor: pointer;" href="data/ei18.pdf"> [PDF]</a>
                            <a style="cursor: pointer;" href="https://www.youtube.com/watch?v=tDC-gHBCTn8"> [Video]</a>
                        </div>
                        <div class="panel" style="display:none; font-size:18px; text-align: justify;">
							<p>Allowing viewers to explore virtual reality in a head-mounted display with six degrees of freedom (6-DoF) greatly enhances the associated immersion and comfort. It makes the experience more compelling compared to a fixed-viewpoint 2-DoF rendering produced by conventional algorithms using data from a stationary camera rig. In this work, we use subjective testing to study the relative importance of, and the interaction between, motion parallax and binocular disparity as depth cues that shape the perception of 3D environments by human viewers. Additionally, we use the recorded head trajectories to estimate the distribution of the head movements of a sedentary viewer exploring a virtual environment with 6-DoF. Finally, we demonstrate a real-time virtual reality rendering system that uses a Stacked OmniStereo intermediary representation to provide a 6-DoF viewing experience by utilizing data from a stationary camera rig. We outline the challenges involved in developing such a system and discuss the limitations of our approach.</p>
						</div>
                    </td>
                </tr>


                <tr>
                    <td class="col-md-3"><img width=250 src="im/vcip17.png"></td>
                    <td class="col-md-9 col-md-offset-0">
                        <div style='font-size:1.5em'>
                            <strong>J. Thatte</strong>, T. Lian, B. Wandell, B. Girod, “Stacked Omnistereo for Virtual Reality with Six Degrees of Freedom”, <i>IEEE Visual Communications and Image Processing (VCIP)</i>, 2017.
                        </div>
                        <div style='font-size:1.5em'>
                            <a style="cursor: pointer;" class='flip' onclick="$(this).next('.panel').slideToggle();"> [Abstract]</a>
                            <a style="cursor: pointer;" href="https://ieeexplore.ieee.org/document/8305085"> [Webpage]</a>
                            <a style="cursor: pointer;" href="data/vcip17.pdf"> [PDF]</a>
                        </div>
                        <div class="panel" style="display:none; font-size:18px; text-align: justify;">
							<p>Motion parallax is an important cue for depth perception. Rendering it accurately can lead to a more natural and immersive virtual reality (VR) experience. We introduce Stacked Omnistereo, a novel data representation that can render immersive video with six degrees of freedom (DoF). We compare the proposed representation against other depth-based and image-based motion parallax techniques using natural as well as synthetic scenes. We show that the proposed representation can synthesize plausible, view-dependent specular highlights, is compact compared to light fields, and outperforms state-of-the-art VR representations by up to 3 dB when evaluated with 6 DoF head motion.</p>
						</div>
                    </td>
                </tr>

                <tr>
                    <td class="col-md-3"><img width=250 src="im/icip16.png"></td>
                    <td class="col-md-9 col-md-offset-0">
						</div>
                        <div style='font-size:1.5em'>
                        <center><i><u>-- Recipient of IEEE SPS Best Paper Award for Industry --</u></i></center>
						</div>
                        <br>
						<div style='font-size:1.5em'>
                            <strong>J. Thatte</strong>, J. -B. Boin, H. Lakshman, G. Wetzstein, B. Girod, “Depth Augmented Stereo Panorama for Cinematic Virtual Reality with Focus Cues”, <i>IEEE International Conference on Image Processing (ICIP)</i>, 2016.
                        </div>
                        <div style='font-size:1.5em'>
                            <a style="cursor: pointer;" class='flip' onclick="$(this).next('.panel').slideToggle();"> [Abstract]</a>
                            <a style="cursor: pointer;" href="https://ieeexplore.ieee.org/document/7532622"> [Webpage]</a>
                            <a style="cursor: pointer;" href="data/icip16.pdf"> [PDF]</a>
                            <a style="cursor: pointer;" href="data/icme16_icip16.zip"> [Supplement]</a>
                            <a style="cursor: pointer;" href="https://signalprocessingsociety.org/sites/default/files/uploads/get_involved/awards/Conference_Best_Paper_Award_for_Industry.pdf"> [Award]</a>
                        </div>
                        <div class="panel" style="display:none; font-size:18px; text-align: justify;">
							<p>Cinematic virtual reality (VR) aims to provide immersive visual experiences of real-world scenes on head-mounted displays. Current cinematic VR systems support stereo cues, but not focus cues that are important for depth perception and comfortable viewing. We propose a new content representation, depth augmented stereo panorama (DASP), which permits generating light fields (LFs) across the observer’s pupils, achieving an order of magnitude reduction in data requirements compared to the existing techniques. The LF generation and refocusing capabilities of DASP are evaluated for both, computer-generated and real scenes. Results indicate that DASP can successfully create stereo as well as support focus cues.</p>
						</div>
                    </td>
                </tr>
 
                <tr>
                    <td class="col-md-3"><img width=250 src="im/icme16.png"></td>
                    <td class="col-md-9 col-md-offset-0">
                        <div style='font-size:1.5em'>
                            <strong>J. Thatte</strong>, J. -B. Boin, H. Lakshman, B. Girod, “Depth Augmented Stereo Panorama for Cinematic Virtual Reality with Head-Motion Parallax”, <i>IEEE International Conference on Multimedia and Expo (ICME)</i>, 2016.
                        </div>
                        <div style='font-size:1.5em'>
                            <a style="cursor: pointer;" class='flip' onclick="$(this).next('.panel').slideToggle();"> [Abstract]</a>
                            <a style="cursor: pointer;" href="https://ieeexplore.ieee.org/document/7552858"> [Webpage]</a>
                            <a style="cursor: pointer;" href="data/icme16.pdf"> [PDF]</a>
                            <a style="cursor: pointer;" href="data/icme16_icip16.zip"> [Supplement]</a>
                        </div>
                        <div class="panel" style="display:none; font-size:18px; text-align: justify;">
							<p>Cinematic virtual reality (VR) aims to provide immersive visual experiences of real-world scenes on head-mounted displays. Current cinematic VR systems employ omnidirectional stereo videos from a fixed position, and therefore do not address head-motion parallax, which is an important cue for depth perception. We propose a new 3D video representation, referred to as depth augmented stereo panorama (DASP), to address this issue. DASP is developed considering data capture, postproduction, streaming, and rendering stages of the VR pipeline. The capabilities of this representation are evaluated by comparing the generated viewports with those from known 3D models. Results indicate that DASP can successfully create stereo and induce head-motion parallax in a predefined operating range.</p>
						</div>
                    </td>
                </tr>
 
            </table>
            </div>

            <h1 id="projects">Projects by Research Area</h1>
            <div class="row">
            <table class="table table-hover">
                <tr>
                    <td class="col-md-12">
                        <div style='font-size:1.5em'>
							<strong>Cinematic Virtual Reality, Head-motion Parallax, and Visual Perception</strong>
                            <a style="cursor: pointer;" class='flip' onclick="$(this).next('.panel').slideToggle();"> [Details]</a>
                        </div>
						<div class="panel" style="display:none; font-size:18px; text-align: justify;">
							<table class="table table-hover">
								<tr>
									<td class="col-md-2">
										June - September 2018
									</td>
									<td class="col-md-3">
										<strong>The Effect of Motion Parallax and Binocular Stereopsis on Viewer Preference and Size Perception in Virtual Reality</strong>
									</td>
									<td class="col-md-7">
										In this work, we show that rendering accurate motion parallax is crucial for a better overall quality of experience in virtual reality. Similarly, rendering a virtual environment in stereo seems to be important for accurate size perception, which is a factor towards making the experience more realistic.
										Poster accepted at ECCV 2018. 
										<a style="cursor: pointer;" href="https://360pi.github.io"> [Website]</a>
										<a style="cursor: pointer;" href="data/eccv18_abs.pdf"> [Structured Abstract]</a>
										<a style="cursor: pointer;" href="data/eccv18.pdf"> [Poster]</a>
										<br><i><u>Keywords:</u></i> Viewer preference, subjective testing, size perception
									</td>
								</tr>
								<tr>
									<td class="col-md-2">
										September 2017 - February 2018
									</td>
									<td class="col-md-3">
										<strong>Towards Perceptual Evaluation of Six Degrees of Freedom Virtual Reality Rendering from Stacked OmniStereo Representation</strong>
									</td>
									<td class="col-md-7">
										We conduct a subjective study to understand the role of motion parallax and stereo vision in viewer preference. We also demonstrate a VR rendering system that takes raw data from a camera rig and after some offline preprocessing renders real-time head-motion parallax. Electronic Imaging Symposium, Conference: PMII 2018.
										<a style="cursor: pointer;" href="https://www.ingentaconnect.com/contentone/ist/ei/2018/00002018/00000005/art00009"> [Webpage]</a>
										<a style="cursor: pointer;" href="data/ei18.pdf"> [PDF]</a>
										<a style="cursor: pointer;" href="https://www.youtube.com/watch?v=tDC-gHBCTn8"> [Video]</a>
										<br><i><u>Keywords:</u></i> cinematic virtual reality, motion parallax, 6 DoF VR
									</td>
								</tr>
								<tr>
									<td class="col-md-2">
										April - December 2017
									</td>
									<td class="col-md-3">
										<strong>Stacked Omnistereo for Virtual Reality with Six Degrees of Freedom</strong><br>Collaboration with Trisha Lian
									</td>
									<td class="col-md-7">
										We propose a novel data representation that can render virtual reality with motion parallax using raw images from a camera rig. IEEE VCIP 2017.
										<a style="cursor: pointer;" href="https://ieeexplore.ieee.org/document/8305085"> [Webpage]</a>
										<a style="cursor: pointer;" href="data/vcip17.pdf"> [PDF]</a>
										<br><i><u>Keywords:</u></i> virtual reality, motion parallax, 6 DoF VR
									</td>
								</tr>
								<tr>
									<td class="col-md-2">
										January-March 2017
									</td>
									<td class="col-md-3">
										<strong>Virtual Reality with Motion Parallax using Facebook Surround-360</strong><br> Collaboration with David Lindell
									</td>
									<td class="col-md-7">
										We demonstrate a novel method of stitching raw images from a camera rig to enable rendering motion parallax.
										<a style="cursor: pointer;" href="data/ee367.pdf"> [PDF]</a>
										<a style="cursor: pointer;" href="data/ee367_poster.pdf"> [Poster]</a>
										<a style="cursor: pointer;" href="data/ee367_code.zip"> [Code]</a>
										<br><i><u>Keywords:</u></i> virtual reality, motion parallax, Facebook Surround 360
									</td>
								</tr>
								<tr>
									<td class="col-md-2">
										March-September 2016
									</td>
									<td class="col-md-3">
										<strong>Depth Augmented Stereo Panorama for Cinematic Virtual Reality with Focus Cues</strong><br> Collaboration with Jean-Baptiste Boin, Haricharan Lakshman, Gordon Wetzstein
									</td>
									<td class="col-md-7">
										We demonstrate a novel data representation that is capable of providing focus cues in virtual reality and is an order of magnitude more compact than light fields and focal stack. IEEE ICIP 2016, IEEE SPS Best Paper for Industry Award.
										<a style="cursor: pointer;" href="https://ieeexplore.ieee.org/document/7532622"> [Webpage]</a>
										<a style="cursor: pointer;" href="data/icip16.pdf"> [PDF]</a>
										<a style="cursor: pointer;" href="data/icme16_icip16.zip"> [Supplement]</a>
										<a style="cursor: pointer;" href="https://signalprocessingsociety.org/sites/default/files/uploads/get_involved/awards/Conference_Best_Paper_Award_for_Industry.pdf"> [Award]</a>
										<br><i><u>Keywords:</u></i> virtual reality, light fields, focus cues
									</td>
								</tr>
								<tr>
									<td class="col-md-2">
										June 2015 - June 2016
									</td>
									<td class="col-md-3">
										<strong>Depth Augmented Stereo Panorama for Cinematic Virtual Reality with Head-Motion Parallax</strong><br> Collaboration with Jean-Baptiste Boin, Haricharan Lakshman
									</td>
									<td class="col-md-7">
										We demonstrate a compact, novel data representation that is capable of rendering virtual reality scenes with motion parallax and produces higher quality novel views compared to state-of-the-art. IEEE ICME 2016.
										<a style="cursor: pointer;" href="https://ieeexplore.ieee.org/document/7552858"> [Webpage]</a>
										<a style="cursor: pointer;" href="data/icme16.pdf"> [PDF]</a>
										<a style="cursor: pointer;" href="data/icme16_icip16.zip"> [Supplement]</a>
										<br><i><u>Keywords:</u></i> virtual reality, head-motion parallax, data representations
									</td>
								</tr>
								<tr>
									<td class="col-md-2">
										April - June 2015
									</td>
									<td class="col-md-3">
										<strong>Rendering of Stereoscopic 360 Views from Spherical Image Pairs</strong><br> Collaboration with Dash Bodington, Matthew Hu
									</td>
									<td class="col-md-7">
										We design a simple VR capturing system comprising 2 vertically displaced Ricoh Theta cameras. The content can be viewed to get a 360 stereo experience.
										<a style="cursor: pointer;" href="data/ee368_project.pdf"> [Report]</a>
										<a style="cursor: pointer;" href="data/ee368_poster.pdf"> [Poster]</a>
										<a style="cursor: pointer;" href="data/ee368_code.pdf"> [Code]</a>
										<br><i><u>Keywords:</u></i> virtual reality, 360 cameras, omnistereo
									</td>
								</tr>
							</table>
						</div>
					</td>
				</tr>
                <tr>
                    <td class="col-md-12">
                        <div style='font-size:1.5em'>
							<strong>Deep Learning</strong>
                            <a style="cursor: pointer;" class='flip' onclick="$(this).next('.panel').slideToggle();"> [Details]</a>
                        </div>
						<div class="panel" style="display:none; font-size:18px; text-align: justify;">
							<table class="table table-hover">
								<tr>
									<td class="col-md-2">
										January-March 2016
									</td>
									<td class="col-md-3">
										<strong>The Essence of Pose</strong><br>Collaboration with Vincent Sitzmann, Timon Ruban, Amir Zamir
									</td>
									<td class="col-md-7">
										We explore several inversion techniques to invert the feature descriptor learned by PoseNet, a CNN trained to understand the 3D pose of objects, to gain insight into the workings of such a network
										<a style="cursor: pointer;" href="data/cs231n.pdf"> [PDF]</a><br>
										<i><u>Keywords:</u></i> CNNs, understanding deep networks, upconvolution
									</td>
								</tr>
								<tr>
									<td class="col-md-2">
										October-December 2015
									</td>
									<td class="col-md-3">
										<strong>Using CNN to Estimate Depth from Stereo Imagery</strong><br>Collaboration with Tyler Jordan, Terry Kong
									</td>
									<td class="col-md-7">
										We train a convolutional neural network on KITTI stereo dataset to estimate stereo disparity from image pairs
										<a style="cursor: pointer;" href="data/cs229.pdf"> [PDF]</a><br>
										<i><u>Keywords:</u></i> CNNs, stereo disparity
									</td>
								</tr>
								<tr>
									<td class="col-md-2">
										January-March 2015
									</td>
									<td class="col-md-3">
										<strong>Simultaneous Visual and Linguistic Embeddings with CNNs and T-LSTMs</strong><br>Collaboration with Nicholas Dufour, Prasanth Vineera
									</td>
									<td class="col-md-7">
										We explore embedding the visual information in scenes and the linguistic information in the corresponding image captions into a common vector space by joint learning. A CNN is used to learn the visual features whereas a tree-structured LSTM network is used for language embedding. A Siamese network is used to push matching vectors closer and the non-matching embeddings father apart.
										<a style="cursor: pointer;" href="data/cs224d.pdf"> [PDF]</a><br>
										<i><u>Keywords:</u></i> CNNs, LSTMs, image captioning
									</td>
								</tr>
							</table>
						</div>
					</td>
				</tr>
				<tr>
                    <td class="col-md-12">
                        <div style='font-size:1.5em'>
							<strong>Features, Descriptors, and Registration</strong>
                            <a style="cursor: pointer;" class='flip' onclick="$(this).next('.panel').slideToggle();"> [Details]</a>
                        </div>
						<div class="panel" style="display:none; font-size:18px; text-align: justify;">
							<table class="table table-hover">
								<tr>
									<td class="col-md-2">
										May-September 2018
									</td>
									<td class="col-md-3">
										<strong>Stereo Image Registration with 3D Model from CT Scan</strong><br><i>Advisory role only</i><br>Project by Lars Jebe
									</td>
									<td class="col-md-7">
										We explore several feature descriptor designs and matching techniques to register the 2.5D point cloud obtained from a stereo image pair against the large, 3D model obtained using CT scan.
										<a style="cursor: pointer;" href="data/registration.pptx"> [Slides]</a><br>
										<i><u>Keywords:</u></i> Feature descriptors, 2.5D registration, point clouds
									</td>
								</tr>
								<tr>
									<td class="col-md-2">
										April 2017 - May 2018
									</td>
									<td class="col-md-3">
										<strong>Light Field Features for Robust SLAM</strong><br><i>Advisory role only, along with Vincent Sitzmann</i><br>Project by Lars Jebe, Donald Dansereau
									</td>
									<td class="col-md-7">
										We develop novel light-field features that we call LiFF. Our work extends SIFT to light-fields and further adds a quality check to filter out non-Lambertian, unstable, or occlusion features.
										<a style="cursor: pointer;" href="data/liff.pdf"> [Slides: Handcrafted LiFF]</a><br>
										<a style="cursor: pointer;" href="data/learned_liff.pptx"> [Slides: Learned LiFF]</a><br>
										<i><u>Keywords:</u></i> Light fields, keypoint detectors, feature descriptors
									</td>
								</tr>
							</table>
						</div>
					</td>
				</tr>
				<tr>
                    <td class="col-md-12">
                        <div style='font-size:1.5em'>
							<strong>Astrophysics</strong>
                            <a style="cursor: pointer;" class='flip' onclick="$(this).next('.panel').slideToggle();"> [Details]</a>
                        </div>
						<div class="panel" style="display:none; font-size:18px; text-align: justify;">
							<table class="table table-hover">
								<tr>
									<td class="col-md-2">
										July 2010 - December 2011
									</td>
									<td class="col-md-3">
										<strong>Asteroseismology of Red Giant Stars</strong><br>Advised by Dr. Anwesh Mazumdar, Tata Institute of Fundamental Research, India
									</td>
									<td class="col-md-7">
										The aim of the project is to use computational techniques and knowledge of the rapidly developing field of Asteroseismology to deduce the internal parameters of a star such as density and pressure profiles, composition, existance and extent of convective core or envelope by analysing its oscillation frequency data.
										<a style="cursor: pointer;" href="data/asteroseismology.pdf"> [PDF]</a><br>
										<i><u>Keywords:</u></i> Stellar Evolution, Stellar Physics, Stellar Modeling
									</td>
								</tr>
								<tr>
									<td class="col-md-2">
										December 2009 - March 2011
									</td>
									<td class="col-md-3">
										<strong>IITMSAT: IIT Madras Student Satellite Initiative</strong><br>in collaboration with Indian Space Research Organization (ISRO)
									</td>
									<td class="col-md-7">
										IITMSAT is a low-earth-orbit nano satellite aimed at detecting bursts of high energy charged particle precipitation below the inner Van-Allen radiation belt due to its interaction with the ULF/VLF waves produced before an earthquake. Such particle counts could thus, in theory, be used to predict earthquakes. I was working on the particle detector / payload team in the founding years of the satellite initiative. I was involved in studying the astrophysical phenomenon to inform mission design as well as designing the first version of the particle detector.
										<a style="cursor: pointer;" href="https://space.skyrocket.de/doc_sdat/iitmsat.htm"> [Website]</a><br>
										<a style="cursor: pointer;" href="data/iitmsat_theory.pdf"> [Particle Bursts as Earthquake Precursors]</a>
										<a style="cursor: pointer;" href="data/iitmsat_design.pdf"> [Particle Detector Electronics]</a><br>
										<i><u>Keywords:</u></i> Geomagnetism, particle detector design, Van-Allen belt
									</td>
								</tr>
								<tr>
									<td class="col-md-2">
										December 2009
									</td>
									<td class="col-md-3">
										<strong>Timing and Spectral Analysis of Galactic Micro-quasars</strong><br>Advised by Dr. Manojendu Choudhury, Tata Institute of Fundamental Research, India
									</td>
									<td class="col-md-7">
										The project was aimed at gaining a better understanding of microquasars from a theoretical perspective. Quasi-periodic oscillations in micro-quasar emissions are vital in extracting their various features. Timing and spectral data of micro-quasars was analyzed to extract these parameters.
										<a style="cursor: pointer;" href="data/microquasars.pdf"> [PDF]</a><br>
										<i><u>Keywords:</u></i> X-ray Astrophysics, Micro-quasars, Fourier Theory
									</td>
								</tr>
							</table>
						</div>
					</td>
				</tr>
				<tr>
                    <td class="col-md-12">
                        <div style='font-size:1.5em'>
							<strong>Modeling and Algorithms</strong>
                            <a style="cursor: pointer;" class='flip' onclick="$(this).next('.panel').slideToggle();"> [Details]</a>
                        </div>
						<div class="panel" style="display:none; font-size:18px; text-align: justify;">
							<table class="table table-hover">
								<tr>
									<td class="col-md-2">
										September-December 2014
									</td>
									<td class="col-md-3">
										<strong>Dynamic Resource Allocation in Heterogeneous Wireless Networks</strong><br>
									</td>
									<td class="col-md-7">
										Two different algorithms -- Q-learning and evolutionary game theory -- were compared in terms of the algorithmic assumptions, computational complexity, and speed of convergence using simulations.
										<a style="cursor: pointer;" href="data/ee359.pdf"> [PDF]</a><br>
										<i><u>Keywords:</u></i> Wireless HetNets, Q-learning, Evolutionary Game Theory
									</td>
								</tr>
								<tr>
									<td class="col-md-2">
										September-December 2014
									</td>
									<td class="col-md-3">
										<strong>Discovering Social Circles in Ego Networks</strong><br>
										Collaboration with Jacob Van Gogh and Ye Yuan
									</td>
									<td class="col-md-7">
										The aim of this project was to automatically social circles in ego networks by studying profiles and connections. These were then evaluated against ground truth social circles manually specified by the users.
										<a style="cursor: pointer;" href="data/cs221.pdf"> [PDF]</a>
										<a style="cursor: pointer;" href="data/cs221_poster.pdf"> [Poster]</a><br>
										<i><u>Keywords:</u></i> Unsupervised learning, clustering
									</td>
								</tr>
								<tr>
									<td class="col-md-2">
										December 2012
									</td>
									<td class="col-md-3">
										<strong>Resistive Memory Devices</strong><br>
										gave a talk at Indo-German Winter Academy, Durgapur, India
									</td>
									<td class="col-md-7">
										I gave a literature survey talk on next generation memory devices, their functioning, and challenges.
										<a style="cursor: pointer;" href="data/igwa_info.png"> [Info]</a>
										<a style="cursor: pointer;" href="data/igwa.pdf"> [Slides]</a><br>
										<i><u>Keywords:</u></i> Resistive memory devices, semiconductor devices
									</td>
								</tr>
								<tr>
									<td class="col-md-2">
										January 2012
									</td>
									<td class="col-md-3">
										<strong>Ant Colony Simulation</strong><br>
										Collaboration with Sagar Sahu
									</td>
									<td class="col-md-7">
										Simulated an ant colony, including finding shortest path, obstacles, births, death, food exploration, and pheromones.<br>
										<a style="cursor: pointer;" href="data/ants.pdf"> [Problem Statement]</a>
										<a style="cursor: pointer;" href="data/ants_solution.pdf"> [Solution]</a>
										<a style="cursor: pointer;" href="data/ants.m"> [Code]</a><br>
										<i><u>Keywords:</u></i> Modeling, simulation
									</td>
								</tr>
								<tr>
									<td class="col-md-2">
										May-July 2010
									</td>
									<td class="col-md-3">
										<strong>Modelling and Parameter Extraction of Organic Semiconductors </strong><br>
										Advised by Dr. K. S. Narayan, JNCASR, India
									</td>
									<td class="col-md-7">
										The goal of the project was to develop a model for organic semiconductors. Thereafter, the focus was on modeling for specific applications: organic solar cells, electron-polymer interfaces, and brain nerve cells.
										<a style="cursor: pointer;" href="data/jncasr.pdf"> [PDF]</a><br>
										<i><u>Keywords:</u></i> Solar cells, modeling, organic semiconductors
									</td>
								</tr>
							</table>
						</div>
					</td>
				</tr>
			</table>
			</div>

            <h1 id="teaching">Teaching</h1>
            <div class="row">
            <table class="table table-hover">

                <tr>
                    <td class="col-md-1"> 
                        <div style='font-size:1.5em'>
                            <a href=""> 
                                <img src="im/su_logo.png"
                                  width="95" style="border-radius: 33px; margin: 10px; max-width: none; margin-left: 0px; margin-top: 0px"
                                  alt="stanford"/>
                            </a> 
                        </div>
                    </td>
                    <td  class="col-md-2">
                        <div style="font-size:1.5em; margin-top: 30px;"> 
                            Winter 2018
                        </div>
                    </td>
                    <td class="col-md-9">
                        <div style='font-size:1.5em'>
                            <strong> Stanford University </strong> <br />
                            EE368: Digital Image Processing
                            <a style="cursor: pointer;" href="https://web.stanford.edu/class/ee368/"> [Website]</a><br>
							Teaching Assistant
                        </div>
                    </td>
                </tr>
                <tr>
                    <td class="col-md-1"> 
                        <div style='font-size:1.5em'>
                            <a href="http://www.iitm.ac.in"> 
                                <img src="im/iitm_logo.png"
                                  width="81" style="border-radius: 39px; margin: 10px; max-width: none; margin-left: 12px; margin-top: 12px"
                                  alt="IIT Madras"/>
                            </a> 
                        </div>
                    </td>
                    <td  class="col-md-2">
                        <div style="font-size:1.5em; margin-top: 20px;"> 
                            Fall 2013
                        </div>
                    </td>
                    <td class="col-md-9">
                        <div style='font-size:1.5em'>
                            <strong> Indian Institute of Technology (IIT) Madras, India </strong> <br />
                            Analog Circuits
                            <a style="cursor: pointer;" href="http://www.ee.iitm.ac.in/videolectures/doku.php?id=ec201:start"> [Website]</a><br>
							EC3102: Teaching Assistant
                        </div>
                    </td>
                </tr>
            </table>
            </div>

            <h1 id="experience">Experience</h1>
            <div class="row">
            <table class="table table-hover">
                <tr>
                    <td class="col-md-2"> 
                        <div style='font-size:1.5em'>
                            <a href="http://softwareforhire.com"> 
                                <img src="im/apple.png"
                                  width="151" style="border-radius: 0px; margin: 10px; max-width: none; margin-left: 0px; margin-top: 0px"
                                  alt="Apple Inc."/>
                            </a> 
                        </div>
                    </td>
                    <td  class="col-md-2">
                        <div style="font-size:1.5em; margin-top: 30px"> 
                            June-September 2016<br>
                            Cupertino, CA, USA
                        </div>
                    </td>
                    <td class="col-md-8">
                        <div style='font-size:1.5em'>
                            <strong>Apple Inc.</strong> <br />
                            <i>Position:</i> Software Engineering Intern<br>
							<i>Keywords:</i> Deep Learning, Novel View Synthesis<br>
                            <i>Project:</i> Worked on developing an algorithm for high-quality novel view synthesis with constrains on total computation. Combined deep learning with classical methods to minimize computation while maintaining the image quality. 
                        </div>
                    </td>
                </tr>
                <tr>
                    <td class="col-md-2"> 
                        <div style='font-size:1.5em'>
                            <a href="http://www.rincon.com/"> 
                                <img src="im/barclays.png"
                                  width="151" style="border-radius: 0px; margin: 10px; max-width: none; margin-left: 0px; margin-top: 0px"
                                  alt="Barclays Bank PLC"/>
                            </a> 
                        </div>
                    </td>
                    <td  class="col-md-2">
                        <div style="font-size:1.5em; margin-top: 30px;"> 
                            May-July-2013<br />
                            Singapore
                        </div>
                    </td>
                    <td class="col-md-8">
                        <div style='font-size:1.5em'>
                            <strong>Barclays Bank PLC</strong> <br>
                            <i>Position:</i> Quantitative Strategist Intern<br>
							<i>Keywords:</i> Statistics, Modelling, Finance<br>
                            <i>Project:</i> Developed a method for predicting profitability of prospective bonds transactions by modeling market movement. Devised a strategy for profitable hedging and identified client groups with potential for revenue enhancement. 
                        </div>
                    </td>
                </tr>
                <tr>
                    <td class="col-md-2"> 
                        <div style='font-size:1.5em'>
                            <a href="http://www.rincon.com/"> 
                                <img src="im/tu_dresden.png"
                                  width="151" style="border-radius: 0px; margin: 10px; max-width: none; margin-left: 0px; margin-top: 20px"
                                  alt="TU Dresden"/>
                            </a> 
                        </div>
                    </td>
                    <td  class="col-md-2">
                        <div style="font-size:1.5em; margin-top: 30px;"> 
                            May-July-2012<br />
                            Dresden, Germany
                        </div>
                    </td>
                    <td class="col-md-8">
                        <div style='font-size:1.5em'>
                            <strong>Technical University Dresden</strong> <br>
                            <i>Position:</i> Research Intern (advised by <a href="https://mns.ifn.et.tu-dresden.de/staff/Gerhard.Fettweis" target="_blank">Prof. Gerard Fettweis</a>)<br>
							<i>Keywords:</i> Wireless Communication, Cognitive Radio, Femtocells<br>
                            <i>Project:</i> Developed an algorithm for cognitive interference management in user-deployed femtocell networks. Each femtocell adjusted its power and frequency in a distributed manner thereby reducing the overall outage probability for end-users and substantially increasing the total network capacity.
                        </div>
                    </td>
                </tr>
                <tr>
                    <td class="col-md-2"> 
                        <div style='font-size:1.5em'>
                            <a href="http://www.rincon.com/"> 
                                <img src="im/bitmapper.jpg"
                                  width="151" style="border-radius: 0px; margin: 10px; max-width: none; margin-left: 0px; margin-top: 20px"
                                  alt="Bitmapper VLSI Solutions"/>
                            </a> 
                        </div>
                    </td>
                    <td  class="col-md-2">
                        <div style="font-size:1.5em; margin-top: 30px;"> 
                            May-July-2011<br />
                            Pune, India
                        </div>
                    </td>
                    <td class="col-md-8">
                        <div style='font-size:1.5em'>
                            <strong>Bitmapper VLSI Solutions</strong> <br>
                            <i>Position:</i> Intern<br>
							<i>Keywords:</i> Digital systems design, FPGA<br>
							<i>Project:</i> I developed an FPGA-based QDR controller IP designed for fast operation and achieved a data transfer rate of 100MBps. I also developed an IP to interface Xilinx FPGA with TI DSP using EMIF bus for high speed signal processing applications. Both the IPs were developed in VHDL and delivered to the client at the end of the internship.
							<a style="cursor: pointer;" href="data/bitmapper.pdf"> [PDF]</a><br>
                        </div>
                    </td>
                </tr>
            </table>
            </div>

            <h1 id="skills">Skills</h1>
            <div class="row">
            <table class="table table-hover">

                <tr>
                    <td class="col-md-2" > 
                        <div style="font-size:1.5em;"> 
                            Programming
                        </div>
                    </td>
                    <td class="col-md-5 col-md-offset-0">
                        <div style='font-size:1.5em'>
						Python, MATLAB, OpenGL, CUDA, C++, Unity3D
                        </div>
                    </td>
                    <td class="col-md-5 col-md-offset-0">
                    </td>
                </tr>

                <tr>
                    <td class="col-md-2" > 
                        <div style="font-size:1.5em;"> 
                            Languages
                        </div>
                    </td>
                    <td class="col-md-5 col-md-offset-0">
                        <div style='font-size:1.5em'>
                        English<br>
                        Hindi  <br>
                        Marathi<br>
						German
						</div>
                    </td>
                    <td class="col-md-5 col-md-offset-0">
                        <div style='font-size:1.5em'>
                        Native/multilingual<br>
                        Native/multilingual<br>
                        Native/multilingual<br>
						Basic
						</div>
                    </td>
                </tr>
                
            </table>
            </div>
            
            <h1 id="contact">Contact</h1>
            <div class="row">
            <table class="table table-hover">
                <tr>
                    <td class="col-md-2" > 
                        <div style="font-size:1.5em;"> 
                            Email
                        </div>
                    </td>
                    <td class="col-md-5 col-md-offset-0">
                        <div style='font-size:1.5em'>
						jayantt [at] stanford [dot] edu
                        </div>
                    </td>
                    <td class="col-md-5 col-md-offset-0">
                    </td>
                </tr>
                <tr>
                    <td class="col-md-2" > 
                        <div style="font-size:1.5em;"> 
                            Office
                        </div>
                    </td>
                    <td class="col-md-5 col-md-offset-0">
                        <div style='font-size:1.5em'>
						Stanford University, 
						David Packard Electrical Engineering,
						350 Serra Mall #353,
						Stanford, CA, 94305
                        </div>
                    </td>
                    <td class="col-md-5 col-md-offset-0">
                    </td>
                </tr>
			</table>
			</div>
            
			</div>

<p>Last updated on May 02, 2020</p>

        </div>


    <!-- jQuery library -->
    <script src="vendor/js/jquery-3.1.1.min.js"></script>
    <script src="vendor/js/bootstrap.min.js"></script>

    <!-- Smooth scrolling to specific parts of the page -->
      

    <script type="text/javascript">
        $(function() {
          $('a[href*="#"]:not([href="#"])').click(function() {
            if (location.pathname.replace(/^\//,'') == this.pathname.replace(/^\//,'') && location.hostname == this.hostname) {
              var target = $(this.hash);
              target = target.length ? target : $('[name=' + this.hash.slice(1) +']');
              if (target.length) {
                topMenu = $("#site_nav")
                topMenuHeight = topMenu.outerHeight() + 5
                $('html, body').animate({
                  scrollTop: target.offset().top - topMenuHeight
                }, 300);
                return false;
              }
            }
          });
        });
      </script>

    <script>
        $(document).ready(function(){
            $(".flip").click(function(){
                $(this).parent().next(".panel").slideToggle("slow");
             });
        });
    </script>


    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-85065092-1', 'auto');
      ga('send', 'pageview');

    </script>




    </body>


</html>
